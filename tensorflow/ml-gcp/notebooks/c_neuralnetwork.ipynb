{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4f3CKqFUqL2-",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives:**\n",
    "  * Use the `DNNRegressor` class in TensorFlow to predict median housing price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is based on 1990 census data from California. This data is at the city block level, so these features reflect the total number of rooms in that block, or the total number of people who live on that block, respectively.\n",
    "<p>\n",
    "Let's use a set of features to predict house value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TjLjL9IU80G"
   },
   "source": [
    "## Set Up\n",
    "In this first cell, we'll load the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = '{:.1f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ipRyUHjhU80Q"
   },
   "source": [
    "Next, we'll load our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://storage.googleapis.com/ml_universities/california_housing_train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzzlSs3PtTmt",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Examine the data\n",
    "\n",
    "It's a good idea to get to know your data a little bit before you work with it.\n",
    "\n",
    "We'll print out a quick summary of a few useful statistics on each column.\n",
    "\n",
    "This will include things like mean, standard deviation, max, min, and various quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-114.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5612.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>472.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>66900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-114.5</td>\n",
       "      <td>34.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7650.0</td>\n",
       "      <td>1901.0</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>80100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>85700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1501.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>73400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-114.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1454.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>624.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>65500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0     -114.3      34.2                15.0       5612.0          1283.0   \n",
       "1     -114.5      34.4                19.0       7650.0          1901.0   \n",
       "2     -114.6      33.7                17.0        720.0           174.0   \n",
       "3     -114.6      33.6                14.0       1501.0           337.0   \n",
       "4     -114.6      33.6                20.0       1454.0           326.0   \n",
       "\n",
       "   population  households  median_income  median_house_value  \n",
       "0      1015.0       472.0            1.5             66900.0  \n",
       "1      1129.0       463.0            1.8             80100.0  \n",
       "2       333.0       117.0            1.7             85700.0  \n",
       "3       515.0       226.0            3.2             73400.0  \n",
       "4       624.0       262.0            1.9             65500.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "gzb10yoVrydW",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2643.7</td>\n",
       "      <td>539.4</td>\n",
       "      <td>1429.6</td>\n",
       "      <td>501.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207300.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2179.9</td>\n",
       "      <td>421.5</td>\n",
       "      <td>1147.9</td>\n",
       "      <td>384.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>115983.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>180400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3151.2</td>\n",
       "      <td>648.2</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>605.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>265000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500001.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
       "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
       "std          2.0       2.1                12.6       2179.9           421.5   \n",
       "min       -124.3      32.5                 1.0          2.0             1.0   \n",
       "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
       "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
       "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
       "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \n",
       "count     17000.0     17000.0        17000.0             17000.0  \n",
       "mean       1429.6       501.2            3.9            207300.9  \n",
       "std        1147.9       384.5            1.9            115983.8  \n",
       "min           3.0         1.0            0.5             14999.0  \n",
       "25%         790.0       282.0            2.6            119400.0  \n",
       "50%        1167.0       409.0            3.5            180400.0  \n",
       "75%        1721.0       605.2            4.8            265000.0  \n",
       "max       35682.0      6082.0           15.0            500001.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is at the city block level, so these features reflect the total number of rooms in that block, or the total number of people who live on that block, respectively.  Let's create a different, more appropriate feature.  Because we are predicing the price of a single house, we should try to make all our features correspond to a single house as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>num_rooms</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>persons_per_house</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>2643.7</td>\n",
       "      <td>539.4</td>\n",
       "      <td>1429.6</td>\n",
       "      <td>501.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207300.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2179.9</td>\n",
       "      <td>421.5</td>\n",
       "      <td>1147.9</td>\n",
       "      <td>384.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>115983.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14999.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1462.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119400.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2127.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>1167.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>180400.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>3151.2</td>\n",
       "      <td>648.2</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>605.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>37937.0</td>\n",
       "      <td>6445.0</td>\n",
       "      <td>35682.0</td>\n",
       "      <td>6082.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500001.0</td>\n",
       "      <td>141.9</td>\n",
       "      <td>34.1</td>\n",
       "      <td>502.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "count    17000.0   17000.0             17000.0      17000.0         17000.0   \n",
       "mean      -119.6      35.6                28.6       2643.7           539.4   \n",
       "std          2.0       2.1                12.6       2179.9           421.5   \n",
       "min       -124.3      32.5                 1.0          2.0             1.0   \n",
       "25%       -121.8      33.9                18.0       1462.0           297.0   \n",
       "50%       -118.5      34.2                29.0       2127.0           434.0   \n",
       "75%       -118.0      37.7                37.0       3151.2           648.2   \n",
       "max       -114.3      42.0                52.0      37937.0          6445.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  num_rooms  \\\n",
       "count     17000.0     17000.0        17000.0             17000.0    17000.0   \n",
       "mean       1429.6       501.2            3.9            207300.9        5.4   \n",
       "std        1147.9       384.5            1.9            115983.8        2.5   \n",
       "min           3.0         1.0            0.5             14999.0        0.8   \n",
       "25%         790.0       282.0            2.6            119400.0        4.4   \n",
       "50%        1167.0       409.0            3.5            180400.0        5.2   \n",
       "75%        1721.0       605.2            4.8            265000.0        6.1   \n",
       "max       35682.0      6082.0           15.0            500001.0      141.9   \n",
       "\n",
       "       num_bedrooms  persons_per_house  \n",
       "count       17000.0            17000.0  \n",
       "mean            1.1                3.0  \n",
       "std             0.5                4.0  \n",
       "min             0.3                0.7  \n",
       "25%             1.0                2.4  \n",
       "50%             1.0                2.8  \n",
       "75%             1.1                3.3  \n",
       "max            34.1              502.5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['num_rooms'] = df['total_rooms'] / df['households']\n",
    "df['num_bedrooms'] = df['total_bedrooms'] / df['households']\n",
    "df['persons_per_house'] = df['population'] / df['households']\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>num_rooms</th>\n",
       "      <th>num_bedrooms</th>\n",
       "      <th>persons_per_house</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>17000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>-119.6</td>\n",
       "      <td>35.6</td>\n",
       "      <td>28.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>207300.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>115983.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-124.3</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14999.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-121.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>119400.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>-118.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>180400.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>-118.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>37.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>265000.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>-114.3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>500001.0</td>\n",
       "      <td>141.9</td>\n",
       "      <td>34.1</td>\n",
       "      <td>502.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  median_income  \\\n",
       "count    17000.0   17000.0             17000.0        17000.0   \n",
       "mean      -119.6      35.6                28.6            3.9   \n",
       "std          2.0       2.1                12.6            1.9   \n",
       "min       -124.3      32.5                 1.0            0.5   \n",
       "25%       -121.8      33.9                18.0            2.6   \n",
       "50%       -118.5      34.2                29.0            3.5   \n",
       "75%       -118.0      37.7                37.0            4.8   \n",
       "max       -114.3      42.0                52.0           15.0   \n",
       "\n",
       "       median_house_value  num_rooms  num_bedrooms  persons_per_house  \n",
       "count             17000.0    17000.0       17000.0            17000.0  \n",
       "mean             207300.9        5.4           1.1                3.0  \n",
       "std              115983.8        2.5           0.5                4.0  \n",
       "min               14999.0        0.8           0.3                0.7  \n",
       "25%              119400.0        4.4           1.0                2.4  \n",
       "50%              180400.0        5.2           1.0                2.8  \n",
       "75%              265000.0        6.1           1.1                3.3  \n",
       "max              500001.0      141.9          34.1              502.5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['total_rooms', 'total_bedrooms', 'population', 'households'], axis = 1, inplace = True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lr6wYl2bt2Ep",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Build a neural network model\n",
    "\n",
    "In this exercise, we'll be trying to predict `median_house_value`. It will be our label (sometimes also called a target). We'll use the remaining columns as our input features.\n",
    "\n",
    "To train our model, we'll first use the [LinearRegressor](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/LinearRegressor) interface. Then, we'll change to DNNRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "featcols = {\n",
    "  colname : tf.feature_column.numeric_column(colname) \\\n",
    "    for colname in 'housing_median_age,median_income,num_rooms,num_bedrooms,persons_per_house'.split(',')\n",
    "}\n",
    "# Bucketize lat, lon so it's not so high-res; California is mostly N-S, so more lats than lons\n",
    "featcols['longitude'] = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('longitude'),\n",
    "                                                   np.linspace(-124.3, -114.3, 5).tolist())\n",
    "featcols['latitude'] = tf.feature_column.bucketized_column(tf.feature_column.numeric_column('latitude'),\n",
    "                                                  np.linspace(32.5, 42, 10).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['num_rooms', 'longitude', 'latitude', 'housing_median_age', 'median_income', 'persons_per_house', 'num_bedrooms'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featcols.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and eval\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "traindf = df[msk]\n",
    "evaldf = df[~msk]\n",
    "\n",
    "SCALE = 100000\n",
    "BATCH_SIZE= 100\n",
    "OUTDIR = './housing_trained'\n",
    "train_input_fn = tf.estimator.inputs.pandas_input_fn(x = traindf[list(featcols.keys())],\n",
    "                                                    y = traindf[\"median_house_value\"] / SCALE,\n",
    "                                                    num_epochs = None,\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle = True)\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(x = evaldf[list(featcols.keys())],\n",
    "                                                    y = evaldf[\"median_house_value\"] / SCALE,  # note the scaling\n",
    "                                                    num_epochs = 1, \n",
    "                                                    batch_size = len(evaldf), \n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_experimental_distribute': None, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_train_distribute': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_task_type': 'worker', '_protocol': None, '_is_chief': True, '_service': None, '_master': '', '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdb0597a0f0>, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_device_fn': None, '_evaluation_master': '', '_tf_random_seed': None, '_model_dir': './housing_trained', '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_experimental_max_worker_delay_secs': None}\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_experimental_distribute': None, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_train_distribute': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_task_type': 'worker', '_protocol': None, '_is_chief': True, '_service': None, '_master': '', '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdb0597a4e0>, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_device_fn': None, '_evaluation_master': '', '_tf_random_seed': None, '_model_dir': './housing_trained', '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_experimental_max_worker_delay_secs': None}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/sparse_ops.py:1719: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_estimator/python/estimator/canned/linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./housing_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 287.47495, step = 1\n",
      "INFO:tensorflow:global_step/sec: 105.888\n",
      "INFO:tensorflow:loss = 51.54384, step = 101 (0.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.306\n",
      "INFO:tensorflow:loss = 48.65148, step = 201 (0.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.052\n",
      "INFO:tensorflow:loss = 126.56402, step = 301 (0.775 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.266\n",
      "INFO:tensorflow:loss = 111.43027, step = 401 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.797\n",
      "INFO:tensorflow:loss = 64.37576, step = 501 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.706\n",
      "INFO:tensorflow:loss = 54.649803, step = 601 (0.784 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.101\n",
      "INFO:tensorflow:loss = 37.535347, step = 701 (0.790 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.497\n",
      "INFO:tensorflow:loss = 175.8621, step = 801 (0.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.282\n",
      "INFO:tensorflow:loss = 48.748768, step = 901 (0.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.398\n",
      "INFO:tensorflow:loss = 112.998535, step = 1001 (0.693 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.238\n",
      "INFO:tensorflow:loss = 30.827982, step = 1101 (0.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 141.163\n",
      "INFO:tensorflow:loss = 110.44106, step = 1201 (0.721 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.924\n",
      "INFO:tensorflow:loss = 58.502525, step = 1301 (0.936 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.242\n",
      "INFO:tensorflow:loss = 68.92865, step = 1401 (0.816 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.779\n",
      "INFO:tensorflow:loss = 63.071964, step = 1501 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.871\n",
      "INFO:tensorflow:loss = 42.043175, step = 1601 (0.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.861\n",
      "INFO:tensorflow:loss = 52.03249, step = 1701 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.105\n",
      "INFO:tensorflow:loss = 42.20678, step = 1801 (0.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.945\n",
      "INFO:tensorflow:loss = 74.194244, step = 1901 (0.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.852\n",
      "INFO:tensorflow:loss = 41.657837, step = 2001 (0.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.862\n",
      "INFO:tensorflow:loss = 48.030235, step = 2101 (0.883 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.337\n",
      "INFO:tensorflow:loss = 42.31994, step = 2201 (0.920 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.894\n",
      "INFO:tensorflow:loss = 165.85786, step = 2301 (0.820 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.949\n",
      "INFO:tensorflow:loss = 39.56925, step = 2401 (0.672 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.368\n",
      "INFO:tensorflow:loss = 49.38209, step = 2501 (0.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 154.393\n",
      "INFO:tensorflow:loss = 24.852013, step = 2601 (0.655 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.494\n",
      "INFO:tensorflow:loss = 66.72681, step = 2701 (0.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 129.599\n",
      "INFO:tensorflow:loss = 56.982136, step = 2801 (0.772 sec)\n",
      "INFO:tensorflow:global_step/sec: 157.87\n",
      "INFO:tensorflow:loss = 42.947884, step = 2901 (0.634 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.912\n",
      "INFO:tensorflow:loss = 83.71588, step = 3001 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.358\n",
      "INFO:tensorflow:loss = 29.049799, step = 3101 (0.765 sec)\n",
      "INFO:tensorflow:global_step/sec: 161.262\n",
      "INFO:tensorflow:loss = 47.21729, step = 3201 (0.619 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.815\n",
      "INFO:tensorflow:loss = 50.276127, step = 3301 (0.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 152.803\n",
      "INFO:tensorflow:loss = 50.68371, step = 3401 (0.657 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.131\n",
      "INFO:tensorflow:loss = 39.628376, step = 3501 (0.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.968\n",
      "INFO:tensorflow:loss = 36.039562, step = 3601 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.169\n",
      "INFO:tensorflow:loss = 65.69611, step = 3701 (0.930 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.271\n",
      "INFO:tensorflow:loss = 108.99754, step = 3801 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.287\n",
      "INFO:tensorflow:loss = 42.75935, step = 3901 (0.723 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.059\n",
      "INFO:tensorflow:loss = 46.0344, step = 4001 (0.737 sec)\n",
      "INFO:tensorflow:global_step/sec: 139.629\n",
      "INFO:tensorflow:loss = 25.931665, step = 4101 (0.724 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.994\n",
      "INFO:tensorflow:loss = 84.26485, step = 4201 (0.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.808\n",
      "INFO:tensorflow:loss = 45.050816, step = 4301 (0.907 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4318 vs previous value: 4318. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 137.093\n",
      "INFO:tensorflow:loss = 58.970192, step = 4401 (0.728 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.751\n",
      "INFO:tensorflow:loss = 49.85243, step = 4501 (0.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 153.309\n",
      "INFO:tensorflow:loss = 54.575775, step = 4601 (0.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.626\n",
      "INFO:tensorflow:loss = 47.870903, step = 4701 (0.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.173\n",
      "INFO:tensorflow:loss = 32.584442, step = 4801 (0.851 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.1034\n",
      "INFO:tensorflow:loss = 57.88279, step = 4901 (1.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.436\n",
      "INFO:tensorflow:loss = 65.0202, step = 5001 (0.843 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.763\n",
      "INFO:tensorflow:loss = 50.84043, step = 5101 (0.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.213\n",
      "INFO:tensorflow:loss = 35.962536, step = 5201 (0.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.596\n",
      "INFO:tensorflow:loss = 81.93528, step = 5301 (0.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.725\n",
      "INFO:tensorflow:loss = 42.812115, step = 5401 (0.860 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.788\n",
      "INFO:tensorflow:loss = 70.20395, step = 5501 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.207\n",
      "INFO:tensorflow:loss = 22.695023, step = 5601 (0.748 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.656\n",
      "INFO:tensorflow:loss = 114.74006, step = 5701 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.476\n",
      "INFO:tensorflow:loss = 51.845596, step = 5801 (0.817 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.171\n",
      "INFO:tensorflow:loss = 69.10307, step = 5901 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.855\n",
      "INFO:tensorflow:loss = 57.167496, step = 6001 (0.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.931\n",
      "INFO:tensorflow:loss = 37.653442, step = 6101 (0.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.827\n",
      "INFO:tensorflow:loss = 100.63837, step = 6201 (0.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.663\n",
      "INFO:tensorflow:loss = 45.680195, step = 6301 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.908\n",
      "INFO:tensorflow:loss = 59.356174, step = 6401 (0.951 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.902\n",
      "INFO:tensorflow:loss = 58.432472, step = 6501 (0.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.656\n",
      "INFO:tensorflow:loss = 25.96526, step = 6601 (0.716 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.434\n",
      "INFO:tensorflow:loss = 33.64456, step = 6701 (0.827 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.694\n",
      "INFO:tensorflow:loss = 73.73861, step = 6801 (0.665 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.459\n",
      "INFO:tensorflow:loss = 40.28419, step = 6901 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.661\n",
      "INFO:tensorflow:loss = 61.12836, step = 7001 (0.864 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.398\n",
      "INFO:tensorflow:loss = 25.05887, step = 7101 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.607\n",
      "INFO:tensorflow:loss = 98.17578, step = 7201 (0.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.488\n",
      "INFO:tensorflow:loss = 39.522808, step = 7301 (0.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.064\n",
      "INFO:tensorflow:loss = 108.78237, step = 7401 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.972\n",
      "INFO:tensorflow:loss = 39.05396, step = 7501 (0.747 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.8358\n",
      "INFO:tensorflow:loss = 95.45867, step = 7601 (1.036 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.074\n",
      "INFO:tensorflow:loss = 85.352356, step = 7701 (0.894 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.6991\n",
      "INFO:tensorflow:loss = 51.237926, step = 7801 (1.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.742\n",
      "INFO:tensorflow:loss = 100.15961, step = 7901 (0.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.7047\n",
      "INFO:tensorflow:loss = 36.03077, step = 8001 (1.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.644\n",
      "INFO:tensorflow:loss = 39.040195, step = 8101 (0.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.18\n",
      "INFO:tensorflow:loss = 38.167324, step = 8201 (0.988 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.032\n",
      "INFO:tensorflow:loss = 84.11547, step = 8301 (0.701 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.953\n",
      "INFO:tensorflow:loss = 27.51427, step = 8401 (0.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.771\n",
      "INFO:tensorflow:loss = 54.76005, step = 8501 (0.841 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.942\n",
      "INFO:tensorflow:loss = 50.378258, step = 8601 (0.722 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 8617 vs previous value: 8617. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 113.356\n",
      "INFO:tensorflow:loss = 112.07545, step = 8701 (0.890 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.829\n",
      "INFO:tensorflow:loss = 58.3661, step = 8801 (0.742 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.891\n",
      "INFO:tensorflow:loss = 68.30821, step = 8901 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.191\n",
      "INFO:tensorflow:loss = 28.946266, step = 9001 (0.786 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.841\n",
      "INFO:tensorflow:loss = 33.867146, step = 9101 (0.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.972\n",
      "INFO:tensorflow:loss = 74.1744, step = 9201 (0.779 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.753\n",
      "INFO:tensorflow:loss = 63.93712, step = 9301 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.005\n",
      "INFO:tensorflow:loss = 68.623184, step = 9401 (0.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.579\n",
      "INFO:tensorflow:loss = 47.729515, step = 9501 (0.853 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.639\n",
      "INFO:tensorflow:loss = 74.9848, step = 9601 (0.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.135\n",
      "INFO:tensorflow:loss = 40.65047, step = 9701 (0.791 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.155\n",
      "INFO:tensorflow:loss = 81.91387, step = 9801 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.7\n",
      "INFO:tensorflow:loss = 36.604137, step = 9901 (0.675 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.453\n",
      "INFO:tensorflow:loss = 46.69189, step = 10001 (0.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.181\n",
      "INFO:tensorflow:loss = 66.05, step = 10101 (0.796 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.754\n",
      "INFO:tensorflow:loss = 123.86021, step = 10201 (0.866 sec)\n",
      "INFO:tensorflow:global_step/sec: 107.094\n",
      "INFO:tensorflow:loss = 52.29534, step = 10301 (0.933 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.487\n",
      "INFO:tensorflow:loss = 48.827198, step = 10401 (0.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.046\n",
      "INFO:tensorflow:loss = 24.474522, step = 10501 (0.926 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.543\n",
      "INFO:tensorflow:loss = 49.75764, step = 10601 (0.803 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.3\n",
      "INFO:tensorflow:loss = 84.35608, step = 10701 (0.686 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.595\n",
      "INFO:tensorflow:loss = 48.986095, step = 10801 (0.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 145.341\n",
      "INFO:tensorflow:loss = 58.315105, step = 10901 (0.689 sec)\n",
      "INFO:tensorflow:global_step/sec: 137.308\n",
      "INFO:tensorflow:loss = 26.89786, step = 11001 (0.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 116.165\n",
      "INFO:tensorflow:loss = 32.135334, step = 11101 (0.854 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.799\n",
      "INFO:tensorflow:loss = 50.52736, step = 11201 (0.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.981\n",
      "INFO:tensorflow:loss = 70.40501, step = 11301 (0.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.748\n",
      "INFO:tensorflow:loss = 53.222137, step = 11401 (0.889 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.596\n",
      "INFO:tensorflow:loss = 80.59563, step = 11501 (0.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.088\n",
      "INFO:tensorflow:loss = 30.995872, step = 11601 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.435\n",
      "INFO:tensorflow:loss = 147.69875, step = 11701 (0.695 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 11750 vs previous value: 11750. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 135.046\n",
      "INFO:tensorflow:loss = 27.86477, step = 11801 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.185\n",
      "INFO:tensorflow:loss = 70.94119, step = 11901 (0.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.984\n",
      "INFO:tensorflow:loss = 58.48547, step = 12001 (0.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.759\n",
      "INFO:tensorflow:loss = 64.52962, step = 12101 (0.911 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 12123 vs previous value: 12123. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 110.983\n",
      "INFO:tensorflow:loss = 87.91462, step = 12201 (0.901 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.046\n",
      "INFO:tensorflow:loss = 64.53301, step = 12301 (0.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.177\n",
      "INFO:tensorflow:loss = 51.384636, step = 12401 (0.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 132.73\n",
      "INFO:tensorflow:loss = 22.959923, step = 12501 (0.751 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.331\n",
      "INFO:tensorflow:loss = 52.724136, step = 12601 (0.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.201\n",
      "INFO:tensorflow:loss = 46.67155, step = 12701 (0.915 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.207\n",
      "INFO:tensorflow:loss = 71.31878, step = 12801 (0.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 142.85\n",
      "INFO:tensorflow:loss = 53.902992, step = 12901 (0.703 sec)\n",
      "INFO:tensorflow:global_step/sec: 127.363\n",
      "INFO:tensorflow:loss = 26.83634, step = 13001 (0.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.115\n",
      "INFO:tensorflow:loss = 50.823235, step = 13101 (0.833 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.738\n",
      "INFO:tensorflow:loss = 118.563545, step = 13201 (0.776 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.514\n",
      "INFO:tensorflow:loss = 41.680008, step = 13301 (0.888 sec)\n",
      "INFO:tensorflow:global_step/sec: 133.937\n",
      "INFO:tensorflow:loss = 102.217255, step = 13401 (0.747 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 13405 vs previous value: 13405. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 115.006\n",
      "INFO:tensorflow:loss = 25.851725, step = 13501 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.67\n",
      "INFO:tensorflow:loss = 51.255165, step = 13601 (0.929 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13630 into ./housing_trained/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-30T01:31:03Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./housing_trained/model.ckpt-13630\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-30-01:31:04\n",
      "INFO:tensorflow:Saving dict for global step 13630: average_loss = 0.5505007, global_step = 13630, label/mean = 2.0638463, loss = 1855.1874, prediction/mean = 2.1122525, rmse = 74195.734\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13630: ./housing_trained/model.ckpt-13630\n",
      "INFO:tensorflow:Loss for final step: 50.47758.\n"
     ]
    }
   ],
   "source": [
    "# Linear Regressor\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  myopt = tf.train.FtrlOptimizer(learning_rate = 0.01) # note the learning rate\n",
    "  estimator = tf.estimator.LinearRegressor(\n",
    "                       model_dir = output_dir, \n",
    "                       feature_columns = featcols.values(),\n",
    "                       optimizer = myopt)\n",
    "  \n",
    "  #Add rmse evaluation metric\n",
    "  def rmse(labels, predictions):\n",
    "    pred_values = tf.cast(predictions['predictions'],tf.float64)\n",
    "    return {'rmse': tf.metrics.root_mean_squared_error(labels*SCALE, pred_values*SCALE)}\n",
    "  estimator = tf.contrib.estimator.add_metrics(estimator,rmse)\n",
    "  \n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = train_input_fn,\n",
    "                       max_steps = num_train_steps)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = eval_input_fn,\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       )\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "\n",
    "# Run training    \n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate(OUTDIR, num_train_steps = (100 * len(traindf)) / BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_experimental_distribute': None, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_train_distribute': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_task_type': 'worker', '_protocol': None, '_is_chief': True, '_service': None, '_master': '', '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdac073ef98>, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_device_fn': None, '_evaluation_master': '', '_tf_random_seed': None, '_model_dir': './housing_trained', '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_experimental_max_worker_delay_secs': None}\n",
      "INFO:tensorflow:Using config: {'_eval_distribute': None, '_experimental_distribute': None, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_train_distribute': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_task_type': 'worker', '_protocol': None, '_is_chief': True, '_service': None, '_master': '', '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdac0f7f400>, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_device_fn': None, '_evaluation_master': '', '_tf_random_seed': None, '_model_dir': './housing_trained', '_global_id_in_cluster': 0, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_experimental_max_worker_delay_secs': None}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./housing_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 460.91217, step = 1\n",
      "INFO:tensorflow:global_step/sec: 70.2594\n",
      "INFO:tensorflow:loss = 119.76516, step = 101 (1.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.1148\n",
      "INFO:tensorflow:loss = 159.55006, step = 201 (1.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0454\n",
      "INFO:tensorflow:loss = 41.685844, step = 301 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7696\n",
      "INFO:tensorflow:loss = 96.94386, step = 401 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.0342\n",
      "INFO:tensorflow:loss = 39.872543, step = 501 (1.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.1183\n",
      "INFO:tensorflow:loss = 111.05566, step = 601 (1.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.0703\n",
      "INFO:tensorflow:loss = 62.371933, step = 701 (1.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.9595\n",
      "INFO:tensorflow:loss = 103.691895, step = 801 (1.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.135\n",
      "INFO:tensorflow:loss = 43.572807, step = 901 (0.899 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.3835\n",
      "INFO:tensorflow:loss = 46.406948, step = 1001 (1.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.9009\n",
      "INFO:tensorflow:loss = 80.334755, step = 1101 (1.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.0731\n",
      "INFO:tensorflow:loss = 63.72539, step = 1201 (1.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.4861\n",
      "INFO:tensorflow:loss = 74.65034, step = 1301 (1.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.2726\n",
      "INFO:tensorflow:loss = 43.517265, step = 1401 (1.083 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.0587\n",
      "INFO:tensorflow:loss = 44.306923, step = 1501 (1.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 112.279\n",
      "INFO:tensorflow:loss = 70.27471, step = 1601 (0.896 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.1729\n",
      "INFO:tensorflow:loss = 66.27003, step = 1701 (1.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.9876\n",
      "INFO:tensorflow:loss = 40.622643, step = 1801 (1.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.343\n",
      "INFO:tensorflow:loss = 51.673923, step = 1901 (0.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.6369\n",
      "INFO:tensorflow:loss = 39.139877, step = 2001 (1.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.597\n",
      "INFO:tensorflow:loss = 91.36007, step = 2101 (0.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.9698\n",
      "INFO:tensorflow:loss = 55.23371, step = 2201 (1.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.8911\n",
      "INFO:tensorflow:loss = 74.62919, step = 2301 (1.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.9805\n",
      "INFO:tensorflow:loss = 64.00069, step = 2401 (1.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.4007\n",
      "INFO:tensorflow:loss = 63.261513, step = 2501 (1.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.8667\n",
      "INFO:tensorflow:loss = 61.872963, step = 2601 (1.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.9875\n",
      "INFO:tensorflow:loss = 51.569027, step = 2701 (1.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.0643\n",
      "INFO:tensorflow:loss = 62.838684, step = 2801 (1.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.1108\n",
      "INFO:tensorflow:loss = 46.284294, step = 2901 (1.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.5076\n",
      "INFO:tensorflow:loss = 46.25404, step = 3001 (1.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.6227\n",
      "INFO:tensorflow:loss = 29.17641, step = 3101 (1.045 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2538\n",
      "INFO:tensorflow:loss = 68.52636, step = 3201 (1.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.2628\n",
      "INFO:tensorflow:loss = 48.19353, step = 3301 (1.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.0079\n",
      "INFO:tensorflow:loss = 50.780518, step = 3401 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.3746\n",
      "INFO:tensorflow:loss = 37.57774, step = 3501 (1.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.6465\n",
      "INFO:tensorflow:loss = 65.936226, step = 3601 (1.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.709\n",
      "INFO:tensorflow:loss = 68.74021, step = 3701 (0.986 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.7044\n",
      "INFO:tensorflow:loss = 94.3596, step = 3801 (1.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.3513\n",
      "INFO:tensorflow:loss = 46.578148, step = 3901 (1.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.7818\n",
      "INFO:tensorflow:loss = 47.53933, step = 4001 (1.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2571\n",
      "INFO:tensorflow:loss = 77.03723, step = 4101 (1.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.5477\n",
      "INFO:tensorflow:loss = 64.18513, step = 4201 (1.031 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0246\n",
      "INFO:tensorflow:loss = 66.742134, step = 4301 (1.337 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.5888\n",
      "INFO:tensorflow:loss = 37.635963, step = 4401 (1.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.7962\n",
      "INFO:tensorflow:loss = 32.279728, step = 4501 (1.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.8744\n",
      "INFO:tensorflow:loss = 55.87739, step = 4601 (1.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.0724\n",
      "INFO:tensorflow:loss = 55.92931, step = 4701 (1.044 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.7465\n",
      "INFO:tensorflow:loss = 52.454002, step = 4801 (1.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.2391\n",
      "INFO:tensorflow:loss = 75.51194, step = 4901 (1.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.2792\n",
      "INFO:tensorflow:loss = 34.360233, step = 5001 (1.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.0351\n",
      "INFO:tensorflow:loss = 61.566093, step = 5101 (1.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.9185\n",
      "INFO:tensorflow:loss = 46.169617, step = 5201 (1.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.194\n",
      "INFO:tensorflow:loss = 72.367226, step = 5301 (0.970 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.9336\n",
      "INFO:tensorflow:loss = 33.692608, step = 5401 (1.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.4352\n",
      "INFO:tensorflow:loss = 82.39173, step = 5501 (1.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.1522\n",
      "INFO:tensorflow:loss = 49.358147, step = 5601 (1.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.2535\n",
      "INFO:tensorflow:loss = 51.9121, step = 5701 (1.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 114.358\n",
      "INFO:tensorflow:loss = 44.704693, step = 5801 (0.874 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1369\n",
      "INFO:tensorflow:loss = 34.000538, step = 5901 (1.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.005\n",
      "INFO:tensorflow:loss = 44.51975, step = 6001 (0.859 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.8003\n",
      "INFO:tensorflow:loss = 51.61851, step = 6101 (1.043 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.6536\n",
      "INFO:tensorflow:loss = 45.236534, step = 6201 (1.014 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.5649\n",
      "INFO:tensorflow:loss = 58.400867, step = 6301 (1.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.014\n",
      "INFO:tensorflow:loss = 38.809082, step = 6401 (0.907 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.7091\n",
      "INFO:tensorflow:loss = 37.954945, step = 6501 (1.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.7898\n",
      "INFO:tensorflow:loss = 84.26751, step = 6601 (1.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.32\n",
      "INFO:tensorflow:loss = 46.348045, step = 6701 (0.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.1412\n",
      "INFO:tensorflow:loss = 84.170685, step = 6801 (1.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.3225\n",
      "INFO:tensorflow:loss = 42.02986, step = 6901 (1.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.5614\n",
      "INFO:tensorflow:loss = 62.28741, step = 7001 (1.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9901\n",
      "INFO:tensorflow:loss = 56.114124, step = 7101 (1.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.6409\n",
      "INFO:tensorflow:loss = 43.856735, step = 7201 (1.303 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.0489\n",
      "INFO:tensorflow:loss = 55.547806, step = 7301 (1.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.6544\n",
      "INFO:tensorflow:loss = 32.23008, step = 7401 (1.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8687\n",
      "INFO:tensorflow:loss = 34.981285, step = 7501 (1.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.0563\n",
      "INFO:tensorflow:loss = 41.675446, step = 7601 (1.020 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.2374\n",
      "INFO:tensorflow:loss = 54.936687, step = 7701 (1.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.077\n",
      "INFO:tensorflow:loss = 47.338074, step = 7801 (0.999 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.7419\n",
      "INFO:tensorflow:loss = 44.92363, step = 7901 (1.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.6416\n",
      "INFO:tensorflow:loss = 32.560192, step = 8001 (1.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.311\n",
      "INFO:tensorflow:loss = 80.43137, step = 8101 (0.839 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1731\n",
      "INFO:tensorflow:loss = 57.34466, step = 8201 (1.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.496\n",
      "INFO:tensorflow:loss = 62.42595, step = 8301 (0.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.1772\n",
      "INFO:tensorflow:loss = 24.8575, step = 8401 (1.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 97.8605\n",
      "INFO:tensorflow:loss = 48.45992, step = 8501 (1.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.8288\n",
      "INFO:tensorflow:loss = 73.02657, step = 8601 (1.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.8033\n",
      "INFO:tensorflow:loss = 42.505398, step = 8701 (1.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3296\n",
      "INFO:tensorflow:loss = 37.2034, step = 8801 (1.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.7827\n",
      "INFO:tensorflow:loss = 49.95896, step = 8901 (1.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 95.3634\n",
      "INFO:tensorflow:loss = 42.54642, step = 9001 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.8801\n",
      "INFO:tensorflow:loss = 47.31093, step = 9101 (1.311 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.3924\n",
      "INFO:tensorflow:loss = 53.148216, step = 9201 (1.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 102.602\n",
      "INFO:tensorflow:loss = 40.508404, step = 9301 (0.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.6266\n",
      "INFO:tensorflow:loss = 31.034557, step = 9401 (1.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.401\n",
      "INFO:tensorflow:loss = 32.23802, step = 9501 (0.972 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.2309\n",
      "INFO:tensorflow:loss = 76.67927, step = 9601 (1.085 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.0226\n",
      "INFO:tensorflow:loss = 42.457012, step = 9701 (1.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.265\n",
      "INFO:tensorflow:loss = 39.37759, step = 9801 (0.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9513\n",
      "INFO:tensorflow:loss = 26.774046, step = 9901 (1.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7523\n",
      "INFO:tensorflow:loss = 36.731804, step = 10001 (1.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.487\n",
      "INFO:tensorflow:loss = 52.201263, step = 10101 (0.967 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.514\n",
      "INFO:tensorflow:loss = 58.93672, step = 10201 (1.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.9471\n",
      "INFO:tensorflow:loss = 41.610092, step = 10301 (1.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.653\n",
      "INFO:tensorflow:loss = 52.824158, step = 10401 (1.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.3648\n",
      "INFO:tensorflow:loss = 34.523952, step = 10501 (1.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.3553\n",
      "INFO:tensorflow:loss = 41.288315, step = 10601 (1.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.4267\n",
      "INFO:tensorflow:loss = 72.21442, step = 10701 (1.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.972\n",
      "INFO:tensorflow:loss = 53.922504, step = 10801 (0.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.6307\n",
      "INFO:tensorflow:loss = 37.81492, step = 10901 (1.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.2099\n",
      "INFO:tensorflow:loss = 60.350716, step = 11001 (1.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.374\n",
      "INFO:tensorflow:loss = 68.8443, step = 11101 (0.987 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.3343\n",
      "INFO:tensorflow:loss = 35.949207, step = 11201 (1.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.2668\n",
      "INFO:tensorflow:loss = 58.968124, step = 11301 (1.093 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.3914\n",
      "INFO:tensorflow:loss = 33.844913, step = 11401 (1.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.8001\n",
      "INFO:tensorflow:loss = 47.28276, step = 11501 (1.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.2555\n",
      "INFO:tensorflow:loss = 64.96611, step = 11601 (1.060 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.1117\n",
      "INFO:tensorflow:loss = 41.26065, step = 11701 (1.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.497\n",
      "INFO:tensorflow:loss = 42.36715, step = 11801 (1.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.1449\n",
      "INFO:tensorflow:loss = 37.156254, step = 11901 (1.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3684\n",
      "INFO:tensorflow:loss = 44.2357, step = 12001 (1.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.1727\n",
      "INFO:tensorflow:loss = 43.48024, step = 12101 (1.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 96.6409\n",
      "INFO:tensorflow:loss = 36.48312, step = 12201 (1.037 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.006\n",
      "INFO:tensorflow:loss = 49.82218, step = 12301 (0.964 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.6761\n",
      "INFO:tensorflow:loss = 35.830322, step = 12401 (1.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7025\n",
      "INFO:tensorflow:loss = 37.546333, step = 12501 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.902\n",
      "INFO:tensorflow:loss = 60.444656, step = 12601 (1.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.7209\n",
      "INFO:tensorflow:loss = 48.531906, step = 12701 (1.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.0548\n",
      "INFO:tensorflow:loss = 50.63847, step = 12801 (1.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.738\n",
      "INFO:tensorflow:loss = 37.471634, step = 12901 (1.006 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.799\n",
      "INFO:tensorflow:loss = 51.263443, step = 13001 (1.286 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.949\n",
      "INFO:tensorflow:loss = 40.624233, step = 13101 (0.968 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.0337\n",
      "INFO:tensorflow:loss = 30.568306, step = 13201 (1.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.8457\n",
      "INFO:tensorflow:loss = 34.050835, step = 13301 (1.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.749\n",
      "INFO:tensorflow:loss = 24.453869, step = 13401 (0.937 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.4649\n",
      "INFO:tensorflow:loss = 38.30046, step = 13501 (1.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.3789\n",
      "INFO:tensorflow:loss = 43.814304, step = 13601 (1.093 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 13630 into ./housing_trained/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-30T01:33:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./housing_trained/model.ckpt-13630\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-30-01:33:42\n",
      "INFO:tensorflow:Saving dict for global step 13630: average_loss = 0.3470195, global_step = 13630, label/mean = 2.0638463, loss = 1169.4557, prediction/mean = 2.0082273, rmse = 58908.367\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13630: ./housing_trained/model.ckpt-13630\n",
      "INFO:tensorflow:Loss for final step: 40.232327.\n"
     ]
    }
   ],
   "source": [
    "# DNN Regressor\n",
    "def train_and_evaluate(output_dir, num_train_steps):\n",
    "  myopt = tf.train.FtrlOptimizer(learning_rate = 0.01) # note the learning rate\n",
    "  estimator = tf.estimator.DNNRegressor(model_dir = output_dir,\n",
    "                                hidden_units = [100, 50, 20],\n",
    "                                feature_columns = featcols.values(),\n",
    "                                optimizer = myopt,\n",
    "                                dropout = 0.1)\n",
    "  \n",
    "  #Add rmse evaluation metric\n",
    "  def rmse(labels, predictions):\n",
    "    pred_values = tf.cast(predictions['predictions'],tf.float64)\n",
    "    return {'rmse': tf.metrics.root_mean_squared_error(labels*SCALE, pred_values*SCALE)}\n",
    "  estimator = tf.contrib.estimator.add_metrics(estimator,rmse)\n",
    "  \n",
    "  train_spec=tf.estimator.TrainSpec(\n",
    "                       input_fn = train_input_fn,\n",
    "                       max_steps = num_train_steps)\n",
    "  eval_spec=tf.estimator.EvalSpec(\n",
    "                       input_fn = eval_input_fn,\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 1, # start evaluating after N seconds\n",
    "                       throttle_secs = 10,  # evaluate every N seconds\n",
    "                       )\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "\n",
    "# Run training    \n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "train_and_evaluate(OUTDIR, num_train_steps = (100 * len(traindf)) / BATCH_SIZE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
