{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "\n",
    "Tensorflow is open source library for numerical computation using data flow graphs. It's data model comprises of tensors, which are basic data units created, manipulated and saved in Tensorflow program. Programming model consists of data flow graphs. Execution model consists of firing nodes of a computation graph in a sequence of dependence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create interactive Tensorflow session using `tfs = tf.InteractiveSession()`. The only difference is that with Interactive session, we get results instantaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = tf.constant(\"Hello tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello tensorflow'\n"
     ]
    }
   ],
   "source": [
    "print(tfs.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensors** are basic elements of computation and a fundamental data structure in Tensorflow. A tensor is an n-dimensional collection of data, identified ny rank, shape and type. *Rank* is the dimension of a tensor, *shape* is the list denoting size in each dimension. A scalar value in a tensor is of rank 0 and has shape of [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow can be created in following ways.\n",
    "- By defining constants, operations and variables and passing the values to their constructor.\n",
    "- By defining placeholders and passing the values to `session.run()`.\n",
    "- By converting Python objects with `tf.convert_to_tensor()` function.\n",
    "\n",
    "Constant valued tensor is created using `tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = tf.constant(5, name='x')\n",
    "c2 = tf.constant(6.0, name='y')\n",
    "c3 = tf.constant(7.0, tf.float32, name='z')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"x:0\", shape=(), dtype=int32)\n",
      "Tensor(\"y:0\", shape=(), dtype=float32)\n",
      "Tensor(\"z:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(c1); print(c2); print(c3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to populate these tensors with value, we need to run it through session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6.0, 7.0]\n"
     ]
    }
   ],
   "source": [
    "print(tfs.run([c1, c2, c3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "op1 = tf.add(c2, c3)\n",
    "print(op1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "op2 = tf.multiply(c2, c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n",
      "42.0\n"
     ]
    }
   ],
   "source": [
    "print(tfs.run(op1))\n",
    "print(tfs.run(op2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Operation Type | Opeartions |\n",
    "|:---------------:|:----------:|\n",
    "| Arithmetic operation | tf.add, tf.subtract, tf.multiply, tf.scalar_mul, tf.div, tf.divide, tf.truediv, tf.floordiv, tf.realdiv, tf.truncatediv, tf.floor_div, tf.truncatemod, tf.floormod, tf.mod, tf.cross |\n",
    "| Math opeartions | tf.add_n, tf.abs, tf.negative, tf.sign, tf.reciprocal, tf.square, tf.round, tf.sqrt, tf.rsqrt, tf.pow, tf.exp, tf.expm1, tf.log, tf.log1p, tf.ceil, tf.floor, tf.maximum, tf.minimum, tf.cos, tf.sin, tf.lbeta, tf.tan, tf.acos, tf.asin, tf.atan, tf.lgamma, tf.digamma, tf.erf, tf.erfc, tf.igamma, tf.squared_difference, tf.igammac, tf.zeta, tf.polygamma, tf.betainc, tf.rint |\n",
    "| Matrix Math operations | tf.diag, tf.diag_part, tf.trace, tf.transpose, tf.eye, tf.matrix_diag, tf.matrix_diag_part, tf.matrix_band_part, tf.matrixz_set_diag, tf.matrix_transpose, tf.matmul, tf.norm, tf.matrix_determinant, tf.matrix_inverse, tf.cholesky, tf.cholesky_solve, tf.matrix_solve, tf.matrix_triangular_solve, tf.matrix_solve_ls, tf.qr, tf.self_adjoint_eig, tf.self_adjoint_eigvals, tf.svd |\n",
    "| Tensor Math operations | tf.tensordot |\n",
    "| Complex number oprerations | tf.complex, tf.conj, tf.imag, tf.real |\n",
    "| String operations | tf.string_to_hash_bucket_fast, tf.string_to_hash_bucket_strong, tf.as_string, tf.encode_base64, tf.decode_base64, tf.reduce_Join, tf.string_join, tf.string_split, tf.substr, tf.string_to_hash_Bucket |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The placeholders allow us to create tensors whose values can be provided at runtime. It provides `tf.placeholder()` method for this which looks like this.\n",
    "\n",
    "```python\n",
    "tf.placeholder(dtype, shape=None, name=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "p1 = tf.placeholder(tf.float32)\n",
    "p2 = tf.placeholder(tf.float32)\n",
    "print(p1); print(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run (op4, {p1: 2.0, p2: 3.0}):  6.0\n"
     ]
    }
   ],
   "source": [
    "op4 = p1 * p2\n",
    "print('run (op4, {p1: 2.0, p2: 3.0}): ', tfs.run(op4, {p1: 2.0, p2: 3.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify the dictionary using `feed_dict` parameter in the `run()` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "print(tfs.run(op4, feed_dict={p1: 2.0, p2: 4.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6. 12. 20.]\n"
     ]
    }
   ],
   "source": [
    "print(tfs.run(op4, feed_dict = {p1: [2.0, 3.0, 4.0], p2: [3.0, 4.0, 5.0]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create tensors from Python objects such as lists and NumPy arrays using `tf.convert_to_tensor()` operation.\n",
    "\n",
    "```python\n",
    "tf.convert_to_tensor(value, dtype=None, name=None, preferred_dtype=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "# Create 0-D tensor\n",
    "tf_t = tf.convert_to_tensor(5.0, dtype=tf.float64)\n",
    "print(tfs.run(tf_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "Tensor(\"Const_2:0\", shape=(5,), dtype=float64)\n",
      "Tensor(\"strided_slice:0\", shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# Create 1-D tensor\n",
    "a1dim = np.array([1,2,3,4,5.99])\n",
    "print(a1dim.shape)\n",
    "tf_t = tf.convert_to_tensor(a1dim, dtype=tf.float64)\n",
    "print(tf_t)\n",
    "print(tf_t[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 2.  , 3.  , 4.  , 5.99])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfs.run(tf_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n",
      "Tensor(\"strided_slice_2:0\", shape=(), dtype=float64)\n",
      "Tensor(\"Const_3:0\", shape=(3, 5), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "a2dim = np.array([(1,2,3,4,5.99),\n",
    "                  (2,3,4,5,6.99),\n",
    "                  (3,4,5,6,7.99)\n",
    "                 ])\n",
    "print(a2dim.shape)\n",
    "tf_t = tf.convert_to_tensor(a2dim, dtype=tf.float64)\n",
    "print(tf_t[0][0])\n",
    "print(tf_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.   2.   3.   4.   5.99]\n",
      " [2.   3.   4.   5.   6.99]\n",
      " [3.   4.   5.   6.   7.99]]\n"
     ]
    }
   ],
   "source": [
    "print(tfs.run(tf_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(tfs.run(tf_t[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tensorflow, variables are tensor objects that hold values that can be modified during the execution of the program. `tf.placeholder` defines input data that does not change over time. `tf.Variable` defines variable values that are modified over time. `tf.placeholder` does not need an initial value at the time of definition. `tf.Variable` needs an initial value at the time of definition.\n",
    "\n",
    "$ y = W $ x $ x + b $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "w: <tf.Variable 'Variable:0' shape=(1,) dtype=float32_ref>\n",
      "b: <tf.Variable 'Variable_1:0' shape=(1,) dtype=float32_ref>\n",
      "x: Tensor(\"Placeholder_2:0\", dtype=float32)\n",
      "y: Tensor(\"add_1:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = w * x + b\n",
    "\n",
    "print('w:', w);\n",
    "print('b:', b)\n",
    "print('x:', x)\n",
    "print('y:', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can use the variables in Tensorflow session, they have to be initialized using `initializer` operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs.run(w.initializer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, we use a convenience function by Tensorflow to initialize all the variables using `tf.global_variables_initializer()` method. It could also be executed using `tf.global_variables_initializer().run()`. We can also initialize specific variables using `tf.variables_initializer()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run(y, {x: [1,2,3,4]}): [0.         0.3        0.6        0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print('run(y, {x: [1,2,3,4]}):', tfs.run(y, {x: [1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors can also be generated from various TensorFlow functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# generate a vector of 100 zeroes and print it.\n",
    "a = tf.zeros((100,))\n",
    "print(tfs.run(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `zeros(shape, dtype=tf.loat32, name=None)` : Creates a tensor with all elements zero.\n",
    "- `zeros_like(tensor, dtype=None, name=None, optimize=True)` : creates a Tensor of same shape as argument, with all elements set to zero.\n",
    "- `ones(shape, dtype=tf.float32, name=None)` : Creates a tensor with all elements set to one.\n",
    "- `ones_like(tensor, dtype=None, name=None, optimize=True)` : Creates a tensor of same shape as argument, with all elements set to one.\n",
    "- `fill(dims, value, name=None)` : Creates a tensor of shape as `dims` argument with all elements set to `value`; for example, `a = tf.fill([100], 0)`.\n",
    "- `lin_space(start, stop, num, name=None)` : Generates a 1-D tensor from a sequence of `num` numbers within the range [start, stop]. Tensor has same data type as `start` argument.\n",
    "- `range(start, limit, delta=1, dtype=None, name='range')` : generates 1-D tensor.\n",
    "- `random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)` : generates a tensor of specific shape, filled with values from a normal distribution.\n",
    "- `truncated_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, seed=None, name=None)` : generates a tensor of specific shape, filled with values from truncated normal distribution. Truncated means that the values returned are always at a distance less than two standard deviations from the mean.\n",
    "- `random_unifrom(shepa,minval=0, maxval=None, dtype=tf.float32, seed=None, name=None)` : generates a tensor filled with values from a uniform distribution.\n",
    "- `random_gamma(shape, alpha, beta=None, dtype=tf.float32, seed=None, name=None)` : generates tensor filled with values from gamma distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we define a variable with a name that has been defined before, then TensorFlow throws an exception. The function `tf.get_variable()` returns the existing variable with the same name if it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.get_variable(name='w', dtype=tf.float32, initializer=[.3])\n",
    "b = tf.get_variable(name='b', dtype=tf.float32, initializer=[-.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In distributed TensorFlow, `tf.get_variable()` gives us global variables. To get the local variables TensorFlow has a function with similar signature: `tf.get_local_variable()`. If `reuse` flag is not set by using `tf.variable_scope.reuse_variable()` or `tf.variable.scope(reuse=True)`, getting already defined variables will throw an exception.\n",
    "\n",
    "A **data flow graph** or **computation graph** is the basic unit of computation in TF. A computation graph is made up of nodes and edges. Each node represents an operation and each edge represents a tensor that gets transferred between nodes. Tensorflow programs are made up of two kinds of operations.\n",
    "1. Building the computation graph\n",
    "2. Running the computation graph\n",
    "\n",
    "Tensorflow comes with default graph. Unless another graph is specified, a new node gets implicitly added to the default graph. We can get explicit access to default graph using `graph = tf.get_default_graph()`. We can execute the operation objects and evaluate tensor objects using session object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  [0.         0.3        0.6        0.90000004]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "# Define model input and output\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = w * x + b\n",
    "output = 0\n",
    "with tf.Session() as tfs:\n",
    "    tf.global_variables_initializer().run()\n",
    "    output = tfs.run(y, {x: [1,2,3,4]})\n",
    "print('output: ', output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nodes are executed in the order of dependency. If we want to control the order in which the nodes are executed in the graph, we can achieve this using `tf.Graph.control_dependencies()`\n",
    "\n",
    "```python\n",
    "with graph_variable.control_dependencies([c,d]):\n",
    "    # other statements\n",
    "```\n",
    "\n",
    "If the graph has nodes a,b,c and d and you want to execute c and d before a and b, above statement helps. This ensures that any node in `with` block is executed only after nodes c and d have been executed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph can be divided into multiple parts and each part can be placed and executed on separate devices, such as CPU or GPU. We can list all devices available for graph execution with below command.\n",
    "\n",
    "```python\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "```\n",
    "\n",
    "Tensorflow implicitly distributes the code across the CPU units and thus by default it shows single CPU. When Tensorflow starts executing graphs, it runs the independent paths within each graph in a separate thread on a separate CPU. We can restrict the number of threads used for this purpose by changing the number of `inter_op_parallelism_threads`. If within an independent path, an operation is capable of running on multiple threads, TensorFlow will launch that operation on multiple threads. The number of threads in this pool can be changed by `intra_op_parallelism_threads`.\n",
    "\n",
    "We can enable logging of variable placement by defining a config object and setting `log_device_placement` to `true`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output [0.         0.3        0.6        0.90000004]\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable([.3], tf.float32)\n",
    "b = tf.Variable([-.3], tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = w * x + b\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement=True\n",
    "with tf.Session(config=config) as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "#     tfs.global_variables_initializer().run()\n",
    "    print('output', tfs.run(y, {x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables and operations can be placed on a specific devices by using `tf.device()` function. Let's say we want to place graph on the CPU.\n",
    "\n",
    "```python\n",
    "tf.reset_default_graph()\n",
    "with tf.device('/device:CPU:0'):\n",
    "    w = tf.get_variable(name='w', initializer=[.3], dtype=tf.float32)\n",
    "    b = tf.get_variable(name='b', initializer=[-.3], dtype=tf.float32)\n",
    "    x = tf.placeholder(name='x', dtype=tf.float32)\n",
    "    y = w * x + b\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement=True\n",
    "\n",
    "with tf.Session(config=config) as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    print('output:', tfs.run(y, {x:[1,2,3,4]}))\n",
    "```\n",
    "\n",
    "Tensorflow follows these placement rules simply:\n",
    "\n",
    "If graph was previously run, the node is left on the device where it was placed earlier.\n",
    "Else if the `tf.device()` block is used, the node is placed on the specified device.\n",
    "Else if the GPU is present, then the node is placed on first available GPU.\n",
    "Else if GPU is not present, then node is placed on the CPU.\n",
    "\n",
    "We can create complicated algorithm for a function which returns device string and we can place node on that device by passing this function to `tf.device()` function. Tensorflow has round robin device setter in `tf.train.replica_device_setter()`.\n",
    "\n",
    "When we place a Tensorflow operation on GPU, the TF must have GPU implementation of that operation (kernel). If it is not present, it results in runtime error. We also get runtime error if that GPU is not present. The best option is to place it on CPU if GPU is not present using `config.allow_soft_placement=True`.\n",
    "\n",
    "When we start running TF session, by default it grabs all GPU memory. If we run another session, we get out of memory error. This could be solve as below.\n",
    "- For multi-GPU systems, set `os.environ['CUDA_VISIBLE_DEVICES'] = '0'`. The code after this setting will be able to grab all memory of only visible GPU.\n",
    "- We can set raction to allocate a percentage of memory using `config.gpu_options.per_process_gpu_memory_fraction = 0.5`. This will allocate 50% of the memory of all GPU devices.\n",
    "- We can also limit the TF process to grab only minimum required memory at the start of process. Later, we can set a config option to allow the growth of memory using `config.gpu_options.allow_growth=True`. This allows only allocated memory to grow, but memory is never released back.\n",
    "\n",
    "We can also create graphs separate from defualt graph and execute them in a session. It is not recommended because creating and using multiple graphs in the same program would require multiple TF sessions and each session would consume heavy resources. Secondly, we cannot directly pass data in between sessions.\n",
    "\n",
    "```python\n",
    "g = tf.Graph() # create new graph\n",
    "output = 0\n",
    "# execute with new graph\n",
    "with g.as_default():\n",
    "    w = tf.Variable([.3], tf.float32)\n",
    "    b = tf.Variable([-.3], tf.float32)\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    y = w * x + b\n",
    "    \n",
    "with tf.Session(graph=g) as tfs:\n",
    "    tf.global_variable_initializer().run()\n",
    "    output = tfs.run(y, {x:[1,2,3,4]})\n",
    "print('output:', output)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "\n",
    "TensorBoard visualizes computation graph structure, provides statistical analysis and plots the values captured as summaries during the execution of graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6]\n"
     ]
    }
   ],
   "source": [
    "# start defining variables for linear model\n",
    "w = tf.Variable([.3], dtype=tf.float32, name='w')\n",
    "b = tf.Variable([-.3], dtype=tf.float32, name='b')\n",
    "x = tf.placeholder(name='x', dtype=tf.float32)\n",
    "y = w * x + b\n",
    "with tf.Session() as tfs:\n",
    "    tfs.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter('tflogs', tfs.graph)\n",
    "    print(tfs.run(y, feed_dict={x:3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cam run tensorboard from shell using `tensorboard --logdir='tflogs'` and open *localhost:6006* url to view Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
